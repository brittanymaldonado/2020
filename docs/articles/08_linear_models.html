<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Introduction to Linear Models: Building and Interpreting Linear Regressions • compbio2020</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Introduction to Linear Models: Building and Interpreting Linear Regressions">
<meta property="og:description" content="compbio2020">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">compbio2020</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/00_Syllabus_and_Expectations.html">Syllabus</a>
    </li>
    <li>
      <a href="../articles/01_Getting_Started_with_R.html">Starting with R</a>
    </li>
    <li>
      <a href="../articles/02_Starting_with_Data.html">Starting with data</a>
    </li>
    <li>
      <a href="../articles/03_Manipulating_Data.html">Manipulating, analyzing and exporting data with tidyverse</a>
    </li>
    <li>
      <a href="../articles/04-plotting.html">Data visualization with ggplot2</a>
    </li>
    <li>
      <a href="../articles/05-Functions.html">Functions and repeatability</a>
    </li>
    <li>
      <a href="../articles/06_Exploration_Setup.html">Exploration</a>
    </li>
    <li>
      <a href="../articles/07_Exploration_Hands_On.html">Exploration Hands-On</a>
    </li>
    <li>
      <a href="../articles/08_linear_models.html">Introduction to Linear Models: Building and Interpreting Linear Regressions</a>
    </li>
    <li>
      <a href="../articles/09_GBIF_and_Location.html">GBIF And Spatial Data</a>
    </li>
    <li>
      <a href="../articles/FunctionReference.html">FunctionReference.Rmd</a>
    </li>
    <li>
      <a href="../articles/HW5.html">Homework Three</a>
    </li>
    <li>
      <a href="../articles/HomeworkFive.html">Homework Five</a>
    </li>
    <li>
      <a href="../articles/HomeworkFour.html">Homework Three</a>
    </li>
    <li>
      <a href="../articles/HomeworkOne.html">Homework One</a>
    </li>
    <li>
      <a href="../articles/HomeworkThree.html">Homework3</a>
    </li>
    <li>
      <a href="../articles/HomeworkTwo.html">Homework Two</a>
    </li>
    <li>
      <a href="../articles/ProjectOne.html">ProjectOne</a>
    </li>
    <li>
      <a href="../articles/ProjectTwo.html">Project Two</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="08_linear_models_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Introduction to Linear Models: Building and Interpreting Linear Regressions</h1>
                        <h4 class="author">Stephanie J. Spielman</h4>
            
            <h4 class="date">Data Science for Biologists, Spring 2020</h4>
      
      
      <div class="hidden name"><code>08_linear_models.Rmd</code></div>

    </div>

    
    
<blockquote>
<p>CAUTION: This is NOT a full-fledged statistics course. This document focuses on performing and interpretting linear regression models rather than their mathematical underpinnings.</p>
</blockquote>
<div id="cheatsheet-chunk" class="section level2">
<h2 class="hasAnchor">
<a href="#cheatsheet-chunk" class="anchor"></a>Cheatsheet chunk</h2>
<div class="sourceCode" id="cb1"><html><body><pre class="r"><span class="co">###### Building linear models with lm ######</span>
<span class="co"># Single predictor</span>
<span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span>(<span class="no">Y</span> ~ <span class="no">X</span>, <span class="kw">data</span> <span class="kw">=</span> <span class="no">dataframe</span>) <span class="kw">-&gt;</span> <span class="no">lm_output</span>

<span class="co"># Multiple independent predictors</span>
<span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span>(<span class="no">Y</span> ~ <span class="no">X</span> + <span class="no">X1</span> + <span class="no">X2</span>, <span class="kw">data</span> <span class="kw">=</span> <span class="no">dataframe</span>) <span class="kw">-&gt;</span> <span class="no">lm_output</span>

<span class="co"># Multiple predictors with an interaction effect</span>
<span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span>(<span class="no">Y</span> ~ <span class="no">X</span>*<span class="no">X1</span>, <span class="kw">data</span> <span class="kw">=</span> <span class="no">dataframe</span>) <span class="kw">-&gt;</span> <span class="no">lm_output</span>


<span class="co">##### Examining linear model output ######</span>
<span class="co"># Standard view of fitted model</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="no">lm_output</span>)

<span class="co"># Tidy views of fitted model with the broom library</span>
<span class="kw pkg">broom</span><span class="kw ns">::</span><span class="fu"><a href="https://broom.tidymodels.org/reference/reexports.html">tidy</a></span>(<span class="no">lm_output</span>)   <span class="co">## Coefficients</span>
<span class="kw pkg">broom</span><span class="kw ns">::</span><span class="fu"><a href="https://broom.tidymodels.org/reference/reexports.html">glance</a></span>(<span class="no">lm_output</span>) <span class="co">## R^2 and other _model fit_ metrics</span>
<span class="kw pkg">broom</span><span class="kw ns">::</span><span class="fu"><a href="https://broom.tidymodels.org/reference/reexports.html">augment</a></span>(<span class="no">lm_output</span>) <span class="co">## Get mmmooorrree information</span>

<span class="co"># Extract model info with the modelr library</span>
<span class="kw pkg">modelr</span><span class="kw ns">::</span><span class="fu"><a href="https://modelr.tidyverse.org/reference/add_residuals.html">add_residuals</a></span>(<span class="no">dataframe</span>, <span class="no">lm_output</span>)    <span class="co"># residuals for each observation</span></pre></body></html></div>
</div>
<div id="note" class="section level1">
<h1 class="hasAnchor">
<a href="#note" class="anchor"></a>Note:</h1>
<p>This week, we have a rare treat. A dear old friend of mine, <a href="https://spielmanlab.github.io/">Stephanie Spielman</a>, has a lesson she’d like some feedback on. You are very welcome to make any comments or suggestions on the <a href="https://github.com/sjspielman/datascience_for_biologists">GitHub Repo</a> for the lesson.</p>
<div id="what-is-a-linear-model" class="section level2">
<h2 class="hasAnchor">
<a href="#what-is-a-linear-model" class="anchor"></a>What is a linear model?</h2>
<p>In statistics and data science, we often want to describe how the value of one variable <em>depends on and/or can be explained/predited by</em> the value of one or more other variables. For example, if we know an individual’s height, could we reasonably predict their weight? Said otherwise: to what extent can height explain variation we see in weight? Potentially we might want to also consider a lot more information like the person’s age, biological sex, health and diet, etc, in addition to just their height. The variable we are interested in predicting (here, <em>weight</em>) is known as the <strong>response/dependent variable</strong>. We are interested in seeing how certain other variables can provide meaningful information about weight, and we call these other variables <strong>predictor/explanatory/independent variables</strong>.</p>
<p>The term “linear model” implies a statistical framework for quantifying to what degree <em>one or more predictor variables</em> describes the variation seen in a <em>response variable</em>. Linear models can answer questions like…</p>
<ul>
<li>Which of the predictor variables show a significant relationship with the response variable?
<ul>
<li>In this case, <em>significant</em> (more or less..) implies that the predictor variable’s values explain, to some degree, variation seen in the response variable. An <em>insignificant</em> (again, more or less..) predictor is one whose explanatory abilities on the variation in the response variable are no different from random chance.</li>
</ul>
</li>
<li>How does do we expect the response value changes, on average, when the predictor value changes?</li>
<li>How much variation in the response variable does each predictor variable explain? And conversely, how much variation in the response variable is unexplained?</li>
</ul>
<p>The mathematical model form of the <em>simplest</em> linear model is:</p>
<p><span class="math display">\[\begin{equation} 
  Y = \beta_1X_1 + \beta_0 + \epsilon
\end{equation}\]</span></p>
<p>The <span class="math inline">\(Y\)</span> is our response, and all <span class="math inline">\(X\)</span> variables are our predictors - in the simple example above, there is a single predictor <span class="math inline">\(X_1\)</span>. Each <span class="math inline">\(\beta\)</span> (Greek letter “beta”) is a given predictor’s <em>coefficient</em>, and they quantify the relationship between each predictor and the response. The <span class="math inline">\(\epsilon\)</span> (Greek letter “epsilon”) represents the <em>error</em> in the model (read on!). In fact, the formula above is actually the formula for a line, or as you may be used to seeing it, <span class="math inline">\(Y = mX + B\)</span>. In our new statistical notation, this <span class="math inline">\(\beta_1\)</span> is the slope <em>m</em>, and this <span class="math inline">\(\beta_0\)</span> is the y-intercept <em>B</em>. More generally for <em>N</em> predictors, we write the model as (rearranged slightly)</p>
<p><span class="math display">\[\begin{equation} \label{eq:full}
  Y =  \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3X_3 ... + \beta_NX_N + \epsilon
\end{equation}\]</span></p>
<p>The error term <span class="math inline">\(\epsilon\)</span> is known as the model’s <em>residuals</em> - how much variation in the response is residual (left over) after considering all the predictors? In other words, what percent of variation in the response variable is unexplained by the predictor variable(s)? It is virtually never true that the predictors will capture 100% of the variation in the response, and the uncaptured percent falls into that <span class="math inline">\(\epsilon\)</span> term.</p>
<p>Practically, what does this formula mean? We can conceptualize this most easily with a simple linear regression (<span class="math inline">\(Y = \beta_1X_1 + \beta_0\)</span>). Finding the line-of-best-fit, which we will call the regression line, is an exercise is finding the best values (aka values with the best <em>fit to the data</em>) for the coefficients <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_0\)</span>.</p>
<p>One of the most common procedures for fitting a model is called <a href="https://en.wikipedia.org/wiki/Ordinary_least_squares">“Ordinary Least Squares,”</a> an algorithm that finds the line (aka best coefficient values!) that minimizes the “sum of squares” of the residuals. The residuals themselves are the <em>distance</em> between each point and the regression line, and the sum of squares in this case is, you guessed, the sum of the squared residuals. We’ll call it “RSS”: the <strong>r</strong>esidual <strong>s</strong>um of <strong>s</strong>quares. Consider this example (images from <a href="https://www.amazon.com/Analysis-Biological-Data-Michael-Whitlock/dp/1936221489">this book</a>) that shows the relationship between the age of a given lion the the proportion of its nose that is black (nose color changes over time for cats and dogs! awwww):</p>
<p><img src="./lm_files/whitlock_17.1-1.png" width="250"></p>
<p>The computer will try to find the best combination of values for the slope (<span class="math inline">\(\beta_1\)</span>) and Y-intercept (<span class="math inline">\(\beta_0\)</span>) that makes the RSS as small as possible by testing out hundreds or thousands of different values. This is what we mean by <strong>fitting a model</strong>: What set of <em>parameter values</em> (fancy word for variables) match the data the best?</p>
<p>In the three images below, we see three different ways this regression line could be drawn. Each line segment from the the point to the regression line is a residual!</p>
<p><img src="./lm_files/whitlock_17.1-2.png" width="600"></p>
<ul>
<li>“Large deviations”: Very high RSS. This line is a poor fit to the data.</li>
<li>“Smaller deviations”: A low RSS. The line is a better, but not best, fit to the data.</li>
<li>“Smallest deviations”: This line represents the line that minimizes the RSS. Its corresponding slope and intercept are our <em>model parameters</em>. It turns out this slope is about <span class="math inline">\(\beta_1 = 10.64\)</span> and the intercept is about <span class="math inline">\(\beta_0 = 0.88\)</span>. Our final fitted model would therefore be <span class="math inline">\(Y = 10.64X_1 + 0.88 + \epsilon\)</span>. In the coming sections we will learn how to interpret these quantities.</li>
</ul>
</div>
<div id="assumption-of-linear-regressions" class="section level2">
<h2 class="hasAnchor">
<a href="#assumption-of-linear-regressions" class="anchor"></a>Assumption of linear regressions</h2>
<p>In this class, we will talk about two general (NOTE: this is a pun, because actually we are talking about “generalized linear models” - you should be aware that my language choice is actually really funny) types of linear models:</p>
<ul>
<li>“Linear regression”, which are used to model <strong>NUMERIC response variables</strong> (this document)</li>
<li>“Logistic regression”, which are used to model <strong>BINARY (categorical) response variables</strong> (e.g., “Yes/No” categories) (a forthcoming document)</li>
</ul>
<p>These models make several key assumptions about the underlying predictors and response variable. These assumptions represent properties in the data itself which must be satisified in order for the models to be reliably interpreted. <strong>Linear regressions are only valid if these assumptions are met:</strong></p>
<ul>
<li>
<strong>Numeric predictors must have a linear relationship with the numeric response.</strong> For example, in the two plots below, the LEFT shows a linear relationship: This data is suitable for analysis with a linear regression. The RIGHT shows a non-linear relationship: This data is not suitable for analysis with a regression (unless you transform) the data.</li>
</ul>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-2-1.png" width="672"></p>
<ul>
<li>
<strong>Categorical predictors should have uniformly-distributed variance</strong>. For example, in the two plots below, the LEFT shows a numeric variable whose different distributions <em>across the categorical variable have about the same spread</em> (although the means differ!): This data is suitable for analysis with a linear regression. The RIGHT shows an example where variance is NOT equally distributed, and this may not be suitable for analysis with a linear regression.</li>
</ul>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-3-1.png" width="672"></p>
<ul>
<li>
<strong>The <em>residuals</em> of the fitted model should be normally-distributed (a bell curve).</strong> There is another type of plot, called a “Q-Q plot” (“quantile-quantile”) we will see later in this document for more carefully examining residuals.</li>
</ul>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-4-1.png" width="672"> + <em>A common misconception</em> for regression is that the data itself must be normally distributed. This is not true! It’s the <em>residuals</em> that must be normally distributed, which can only be examined after the model is fitted. Again, there is no requirement that numeric predictors themselves or the response itself be normally distributed!!</p>
<div id="analyses-that-are-actually-all-linear-regression-models" class="section level3">
<h3 class="hasAnchor">
<a href="#analyses-that-are-actually-all-linear-regression-models" class="anchor"></a>Analyses that are actually all linear regression models</h3>
<p>You will often hear these fancy statistical names for different hypothesis tests. Fundamentally, they are all linear regressions with different types of predictors. Really there is no need to distinguish them!! You just need to know how to interpret predictor coefficients, and you can make any model you want. Again, all linear regressions have a <strong>numeric response</strong>.</p>
<ul>
<li>Correlation: Read on to the the next section!!</li>
<li>Simple linear regression: Models with a single <em>numeric</em> predictor variable</li>
<li>Multiple linear regression: Models with several <em>numeric</em> predictor variable</li>
<li>ANOVA (<strong>An</strong>alysis <strong>o</strong>f <strong>Va</strong>riance): Models with a single <em>categorical</em> predictor variable</li>
<li>MANOVA (<strong>M</strong>ultivariate <strong>An</strong>alysis <strong>o</strong>f <strong>Va</strong>riance): Models with a multiple <em>categorical</em> predictor variables</li>
<li>ANCOVA (<strong>An</strong>alysis of <strong>Cova</strong>riance): Models with a single <em>categorical</em> AND one or more <em>numeric</em> predictor variables</li>
<li>MANCOVA (<strong>M</strong>ultivariate <strong>An</strong>alysis of <strong>Cova</strong>riance): Models with multiple <em>categorical</em> AND multiple <em>numeric</em> predictor variables</li>
</ul>
<p>In fact, so are hypothesis tests like <em>t</em>-tests, and similarly all their non-parametric equivalents - Mann-Whitney aka Wilcoxon, sign test, and Kruskal-Wallis test. <a href="https://lindeloev.github.io/tests-as-linear/">This post</a> goes into extensive depth about the how and why of this Truth.</p>
</div>
<div id="briefly-correlation" class="section level3">
<h3 class="hasAnchor">
<a href="#briefly-correlation" class="anchor"></a>Briefly, correlation</h3>
<p>A closely related (both conceptually and mathematically) topic here is <em>correlation</em>, which is a quantity that tells us whether two variables appear to be associated, or non-independent. <strong>Correlation does NOT IMPLY causation</strong> - it merely implies an observable pattern of association. There are many different wants to quantify a correlation, but perhaps the most commonly-used one is Pearson correlation. This quantity measures strength and direction a of <strong>linear</strong> association between normally-distributed numeric variables - it is virtually mathematically equivalent to a simple linear regression. This is measured with the correlation coefficient <em>r</em> which can be any value in <span class="math inline">\(-1 \leq r \leq 1\)</span>. Below are shown examples of data with PERFECT correlations: there is a perfect x-y association, but the directions are different. There is also an example of NO correlation.</p>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-5-1.png" width="624"></p>
<p>The strength of the relationship is heavily influenced by <em>noise</em> (images from <a href="https://www.amazon.com/Analysis-Biological-Data-Michael-Whitlock/dp/1936221489">this book</a>). The farther points are from the middle, the more error (residuals!!) there is, and hence the lower the correlation.</p>
<p><img src="./lm_files/whitlock_16.6-1.png" width="600"></p>
<p><strong>But be careful!!</strong> The computer will still calculate a correlation even if the data is not linearly related! The correlatio below is NOT VALID because the assumption of linearity has not been met. Always plot your data!!!</p>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-6-1.png" width="288"></p>
<p>There are other types of correlations that can be employed (for example, Spearman rank correlation) when the data is not linearly related. Fundamentally, if you run a linear regression, you have implicitly run a correlation. Have some fun with correlations by <a href="http://guessthecorrelation.com/">practicing guessing the value for <em>r</em></a>.</p>
</div>
</div>
<div id="examples-and-interpretation" class="section level2">
<h2 class="hasAnchor">
<a href="#examples-and-interpretation" class="anchor"></a>Examples and interpretation</h2>
<p>All examples will use the external dataset <code>crabs</code> and assume <span class="math inline">\(\alpha=0.05\)</span>. This dataset contains physical measurements from 200 crabs, including their sex (M/F), color (orange or blue), and various other quantities measured in millimeters (mm). <strong>The goal of these examples is model body depth in crabs. Therefore, the column <code>body_depth</code> is our response variable.</strong></p>
<div class="sourceCode" id="cb2"><html><body><pre class="r"><span class="no">crabs</span> <span class="kw">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"https://raw.githubusercontent.com/sjspielman/datascience_for_biologists/master/spring2020/rmd_lessons/lm_files/crabs.csv"</span>)
<span class="co">## Parsed with column specification:</span>
<span class="co">## cols(</span>
<span class="co">##   color = col_character(),</span>
<span class="co">##   sex = col_character(),</span>
<span class="co">##   frontal_lobe = col_double(),</span>
<span class="co">##   rear_width = col_double(),</span>
<span class="co">##   carapace_length = col_double(),</span>
<span class="co">##   carapace_width = col_double(),</span>
<span class="co">##   body_depth = col_double()</span>
<span class="co">## )</span>
<span class="kw pkg">dplyr</span><span class="kw ns">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/reexports.html">glimpse</a></span>(<span class="no">crabs</span>)
<span class="co">## Rows: 200</span>
<span class="co">## Columns: 7</span>
<span class="co">## $ color           &lt;chr&gt; "blue", "blue", "blue", "blue", "blue", "blue", "blue…</span>
<span class="co">## $ sex             &lt;chr&gt; "M", "M", "M", "M", "M", "M", "M", "M", "M", "M", "M"…</span>
<span class="co">## $ frontal_lobe    &lt;dbl&gt; 8.1, 8.8, 9.2, 9.6, 9.8, 10.8, 11.1, 11.6, 11.8, 11.8…</span>
<span class="co">## $ rear_width      &lt;dbl&gt; 6.7, 7.7, 7.8, 7.9, 8.0, 9.0, 9.9, 9.1, 9.6, 10.5, 10…</span>
<span class="co">## $ carapace_length &lt;dbl&gt; 16.1, 18.1, 19.0, 20.1, 20.3, 23.0, 23.8, 24.5, 24.2,…</span>
<span class="co">## $ carapace_width  &lt;dbl&gt; 19.0, 20.8, 22.4, 23.1, 23.0, 26.5, 27.1, 28.4, 27.8,…</span>
<span class="co">## $ body_depth      &lt;dbl&gt; 7.0, 7.4, 7.7, 8.2, 8.2, 9.8, 9.8, 10.4, 9.7, 10.3, 1…</span></pre></body></html></div>
<div id="simple-linear-regression-single-numeric-predictor" class="section level3">
<h3 class="hasAnchor">
<a href="#simple-linear-regression-single-numeric-predictor" class="anchor"></a>Simple linear regression: Single numeric predictor</h3>
<p>Let’s begin with a simple regression to examine the relationship between <strong>carapace length</strong> and <strong>body depth</strong>, specifically to what extent body depth can be explained by carapace length. Therefore, carapace length is our predictor (X) variable, and body depth is our response (Y) variable.</p>
<p><strong>The very first thing we should do is VISUALIZE our data</strong> . Make sure that each numeric predictor (in this case there is only 1!) indeed has a roughly <em>linear relationship</em> to the response. Indeed, this relationship looks linear, and apparantly (quite strongly!) positively related, so we are good to go.</p>
<div class="sourceCode" id="cb3"><html><body><pre class="r"><span class="co"># predictor goes on X, response goes on Y</span>
<span class="fu">ggplot</span>(<span class="no">crabs</span>, <span class="fu">aes</span>(<span class="kw">x</span> <span class="kw">=</span> <span class="no">carapace_length</span>, <span class="kw">y</span> <span class="kw">=</span> <span class="no">body_depth</span>)) +
  <span class="fu">geom_point</span>()</pre></body></html></div>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-8-1.png" width="384"></p>
<p>We perform regressions using the function <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> (any guesses what this stands for?).</p>
<div class="sourceCode" id="cb4"><html><body><pre class="r"><span class="co">## perform linear regression and save as model_fit</span>
<span class="co">## Y ~ X !!!!!!!!!!!!!! </span>
<span class="co">## RESPONSE ~ PREDICTOR !!!!!!!!!!!!!!!!</span>
<span class="no">model_fit</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span>(<span class="no">body_depth</span> ~ <span class="no">carapace_length</span>, <span class="kw">data</span> <span class="kw">=</span> <span class="no">crabs</span>)

<span class="co">## view output with summary(). Ugly, useful for getting a visual overview.</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="no">model_fit</span>)</pre></body></html></div>
<pre><code>## 
## Call:
## lm(formula = body_depth ~ carapace_length, data = crabs)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.96587 -0.47864  0.07071  0.49976  1.43543 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     -1.15527    0.20517  -5.631 6.09e-08 ***
## carapace_length  0.47300    0.00624  75.803  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.6266 on 198 degrees of freedom
## Multiple R-squared:  0.9667, Adjusted R-squared:  0.9665 
## F-statistic:  5746 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="interpreting-the-model-output" class="section level3">
<h3 class="hasAnchor">
<a href="#interpreting-the-model-output" class="anchor"></a>Interpreting the model output</h3>
<ul>
<li><p><strong>Call</strong> simply reminds us of the linear model formula we specified when using <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code>.</p></li>
<li><p><strong>Residuals</strong> shows the <em>five-number summary</em> of the distribution of the residuals.</p></li>
<li><p><strong>Coefficients</strong> tell us our <span class="math inline">\(\beta\)</span> values. Their <em>Estimate</em> is the value the model returned, Their <em>Std. Error</em> indicates how close/far these model estimates, derived from the sample, likely are from the “true” population values. The <em>t value</em> is <em>t</em> statistic associated with the estimate’s significance, and the final column <em>Pr(&gt;|t|)</em> is the P-value associated with the <em>t</em> statistic - it tells us if the coefficient is significant or not. The null hypothesis for any coefficient is “Coefficient = 0.” Therefore, a significant predictor coefficient means we are fairly sure it’s value is not 0.</p></li>
<li><p><strong>(Intercept)</strong> is our fitted value for <span class="math inline">\(\beta_0\)</span>. It tells us: What is the EXPECTED VALUE of the response variable when the numeric predictor value is 0? In this case, what do we expect the average body depth will be when a crab’s carapace length is 0 mm? Here, we expect that crabs will have a body depth of -1.155 mm, on average, when their carapace length is 0. We can also write this as -1.155±0.205 mm to acknowledge the standard error! This is of course NOT realistic and illustrates perfectly that you need to be careful to interpret coefficients with biological intuition! Just because the computer spits out a number doesn’t mean it’s meaningful. No crabs will have a body depth of 0mm. Regardless, this quantity needs to be here to fulfill the mathematical model itself - we’re just smart enough to know that the mathematical model is terrible at biology. The intercept is highly significant (<em>P=6.09e-08</em>). Therefore, there is evidence the intercept differs from 0.</p></li>
<li><p><strong>carapace_length</strong> is our fitted value for <span class="math inline">\(\beta_1\)</span>. It tells us: What is the EXPECTED change of the response the predictor increases by a unit of 1? In this case, by how much do we expect body depth will increase/decrease when the carapace length goes up by 1? Here, we expect for every 1 mm increase in carapace length, body depth will <em>increases</em> by 0.473 mm (or, 0.473±0.00624 mm). Remember in this case, this value is the slope (0.473 = rise/run = <span class="math inline">\(\Delta\)</span>body depth/<span class="math inline">\(\Delta\)</span>carapace length = 0.473/1 = 0.473 increase in body depth for ever 1 increase in carapace length). The P-value here is highly significant at <em>P&lt;2.2e-16</em> (this is nearly R’s lower bound for reporting tiny P-values), so we quite confident that the true value indeed differs from 0.</p></li>
<li><p><strong>Residual standard error</strong>: The standard error associated with residuals. The closer this value is to 0, the better our model fit. We won’t focus much on this quantity, but be aware that large values here indicate the model is rather poor. This value of 0.6266 is fairly small.</p></li>
<li><p><strong>Multiple R-squared</strong> and <strong>Adjusted R-squared</strong> give the <span class="math inline">\(R^2\)</span> associated with the model. <strong>A model’s <span class="math inline">\(R^2\)</span> tells you the percent of variation in the response that can be explained by the predictors</strong>. This is SUPER important (and note, it is actually the squared Pearson correlation coefficient!). The “Adjusted R-squared” is somewhat more reliable for consideration - it corrects for any overfitting artifacts inherent in modeling, so focus on this value. It’s associated P-value is on the next line (here, <em>P&lt;2.2e-16</em>), and the associated null hypothesis for this P-value is <span class="math inline">\(R^2 = 0\)</span>. <strong>In this model, 96.65% of the variation in body depth can be explained by carapace lengths. 3.35% of the varation in body depth is therefore UNEXPLAINED by our model.</strong> That 3.35% is sneakily hidden in the <span class="math inline">\(\epsilon\)</span> term of the fitted linear model formula. This <span class="math inline">\(R^2\)</span> is very close to 1 (100%) - this is <em>a really really good model</em>.</p></li>
</ul>
<div id="conclusions" class="section level4">
<h4 class="hasAnchor">
<a href="#conclusions" class="anchor"></a>Conclusions:</h4>
<ul>
<li>Our fitted model is <span class="math inline">\(Y = 0.473X - 1.16 + \epsilon\)</span>
</li>
<li>~96.65% of variation in crab body depth can be explained by carapace length.</li>
<li>For every 1 mm increase in carapace length, we expect body depth to increase, on average, by 0.473 mm.</li>
</ul>
</div>
</div>
<div id="visualizing-the-model" class="section level3">
<h3 class="hasAnchor">
<a href="#visualizing-the-model" class="anchor"></a>Visualizing the model</h3>
<p>We can visualize this output with a scatterplot and <code>geom_smooth()</code>! This is why we’ve been saying <code>method = "lm"</code> in <code>geom_smooth()</code> - this function adds a trendline, and by specify “lm” we are telling <code>geom_smooth()</code> to use a linear model to determine the trendline:</p>
<div class="sourceCode" id="cb6"><html><body><pre class="r"><span class="co"># predictor goes on X, response goes on Y</span>
<span class="fu">ggplot</span>(<span class="no">crabs</span>, <span class="fu">aes</span>(<span class="kw">x</span> <span class="kw">=</span> <span class="no">carapace_length</span>, <span class="kw">y</span> <span class="kw">=</span> <span class="no">body_depth</span>)) +
  <span class="fu">geom_point</span>(<span class="kw">size</span> <span class="kw">=</span> <span class="fl">0.5</span>) +        <span class="co">## making the points small to help see the regression line</span>
  <span class="fu">geom_smooth</span>(<span class="kw">method</span> <span class="kw">=</span> <span class="st">"lm"</span>,     <span class="co">## make a trendline using "lm"</span>
              <span class="kw">color</span> <span class="kw">=</span> <span class="st">"navy"</span>,    <span class="co">## make the trendline navy</span>
              <span class="kw">size</span> <span class="kw">=</span> <span class="fl">0.5</span>,        <span class="co">## make the line small to help see the confidence interval for TUTORIAL REASONS</span>
              <span class="kw">fill</span> <span class="kw">=</span> <span class="st">"deeppink4"</span>) + <span class="co">## fill for the confidence interval</span>
  <span class="fu">labs</span>(<span class="kw">x</span> <span class="kw">=</span> <span class="st">"Carapace length (mm)"</span>,
       <span class="kw">y</span> <span class="kw">=</span> <span class="st">"Body depth (mm)"</span>,
       <span class="kw">title</span> <span class="kw">=</span> <span class="st">"Linear regression to predict crab body depth"</span>) +
  <span class="fu">annotate</span>(<span class="st">"text"</span>,                <span class="co">## geom to annotate with is text annotation</span>
           <span class="kw">x</span> <span class="kw">=</span> <span class="fl">20</span>, <span class="kw">y</span> <span class="kw">=</span> <span class="fl">30</span>,         <span class="co">## coordinates of the label, decided after trying several places..</span>
           <span class="kw">label</span> <span class="kw">=</span> <span class="st">"R^2 == 0.966"</span>, <span class="co">## label itself, double equals is needed for use with parse=T</span>
           <span class="kw">parse</span><span class="kw">=</span><span class="no">T</span>,               <span class="co">## makes label actually show as a formula, with squared as superscript!</span>
           <span class="kw">color</span> <span class="kw">=</span> <span class="st">"firebrick"</span>, <span class="kw">size</span> <span class="kw">=</span> <span class="fl">5</span>)  + <span class="co">## font color and size </span>
  <span class="fu">theme_bw</span>()</pre></body></html></div>
<pre><code>## `geom_smooth()` using formula 'y ~ x'</code></pre>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-10-1.png" width="576"></p>
<p><strong>Critical followup: What is a confidence interval?</strong> A confidence interval (CI) is meant to help convey <em>error</em> in the estimate - in this case, the confidence bands you see (pink area around the line) represents the error associated with our fitted slope aka our model’s <span class="math inline">\(\beta_1\)</span> estimate! It is directly related to “standard error”, so in the function <code>geom_smooth()</code> you can turn it off as <code>geom_smooth(se=F)</code> to not display it.</p>
<p>Loosely speaking, a <em>95% CI</em> (ggplot and many others use 95% confidence interval by default) means: Assuming all the lovely assumptions of our statistical framework, there is 95% probability that the TRUE VALUE OF THE SLOPE is within the CI. Stated more accurately, if you took N random samples of crabs and calculated their regressions of body depth across carapace length, line (slope and intercept!) would fall within the 95% shaded area CI for 95% of the samples.</p>
<p><strong>For an excellent intuitive understanding of what this means, see <a href="https://github.com/wilkelab/ungeviz">the second plot example in this package’s README</a>.</strong></p>
</div>
<div id="checking-the-assumption-of-normal-residuals" class="section level3">
<h3 class="hasAnchor">
<a href="#checking-the-assumption-of-normal-residuals" class="anchor"></a>Checking the assumption of normal residuals</h3>
<p>One of the assumptions of linear regressions is that residuals should be normally distributed. Residuals are calculated as part of the model itself, so the goal is to check the residuals AFTER you perform the model to see if it worked out ok. If the residuals are severely not normal, it means there were some problems with the model itself and you need to rethink your approach - which predictors to include/exclude? add in interaction effect [keep reading!!]? transform some of the data?</p>
<p>We can check this assumption using a <strong>Q-Q plot</strong>, specifically a NORMAL QQ plot which shows the relationship between your data and a <em>theoretical prediction</em> for what the data would like if it were normally distributed. If the data falls roughly in a straight line, the data is distributed normally!!! If not, not normal :(</p>
<p>First, we need to get the residuals themselves out of the model - my preferred way for doing this uses the <code>broom()</code> package. This packages tidies (sweeps up?…sigh.) model output into nice little tibbles, and it has three main functions we want: <code><a href="https://broom.tidymodels.org/reference/reexports.html">broom::tidy()</a></code>, <code><a href="https://broom.tidymodels.org/reference/reexports.html">broom::glance()</a></code>, and <code><a href="https://broom.tidymodels.org/reference/reexports.html">broom::augment()</a></code>. The first two are nice for collecting the ugly summary data into tibbles. We simply pass in the model output itself.</p>
<div class="sourceCode" id="cb8"><html><body><pre class="r"><span class="co"># redefining model just to orient you back</span>
<span class="no">model_fit</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span>(<span class="no">body_depth</span> ~ <span class="no">carapace_length</span>, <span class="kw">data</span> <span class="kw">=</span> <span class="no">crabs</span>)

<span class="co"># assumes broom library is loaded! </span>
<span class="co"># it comes installed with tidyverse, but needs to be loaded with library(broom) in the setup chunk.</span>
<span class="co"># Gives coefficients in tidy form</span>
<span class="kw pkg">broom</span><span class="kw ns">::</span><span class="fu"><a href="https://broom.tidymodels.org/reference/reexports.html">tidy</a></span>(<span class="no">model_fit</span>)</pre></body></html></div>
<pre><code>## # A tibble: 2 x 5
##   term            estimate std.error statistic   p.value
##   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)       -1.16    0.205       -5.63 6.09e-  8
## 2 carapace_length    0.473   0.00624     75.8  3.13e-148</code></pre>
<div class="sourceCode" id="cb10"><html><body><pre class="r"><span class="co"># Gives R^2 (and some other values, stay tuned!!!) in tidy form</span>
<span class="kw pkg">broom</span><span class="kw ns">::</span><span class="fu"><a href="https://broom.tidymodels.org/reference/reexports.html">glance</a></span>(<span class="no">model_fit</span>)</pre></body></html></div>
<pre><code>## # A tibble: 1 x 12
##   r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC
##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     0.967         0.967 0.627     5746. 3.13e-148     1  -189.  385.  395.
## # … with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb12"><html><body><pre class="r"><span class="co">## Gives a whoooole bunch of under-the-hood info in tidy form - tacked onto the data itself!!!</span>
<span class="kw pkg">broom</span><span class="kw ns">::</span><span class="fu"><a href="https://broom.tidymodels.org/reference/reexports.html">augment</a></span>(<span class="no">model_fit</span>)</pre></body></html></div>
<pre><code>## # A tibble: 200 x 8
##    body_depth carapace_length .fitted   .resid .std.resid    .hat .sigma .cooksd
##         &lt;dbl&gt;           &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
##  1        7              16.1    6.46  0.540      0.875   0.0304   0.627 1.20e-2
##  2        7.4            18.1    7.41 -0.00596   -0.00963 0.0244   0.628 1.16e-6
##  3        7.7            19      7.83 -0.132     -0.212   0.0220   0.628 5.08e-4
##  4        8.2            20.1    8.35 -0.152     -0.245   0.0193   0.628 5.90e-4
##  5        8.2            20.3    8.45 -0.247     -0.397   0.0188   0.628 1.51e-3
##  6        9.8            23      9.72  0.0764     0.123   0.0132   0.628 1.01e-4
##  7        9.8            23.8   10.1  -0.302     -0.485   0.0118   0.628 1.41e-3
##  8       10.4            24.5   10.4  -0.0331    -0.0532  0.0107   0.628 1.53e-5
##  9        9.7            24.2   10.3  -0.591     -0.949   0.0112   0.627 5.10e-3
## 10       10.3            25.2   10.8  -0.464     -0.744   0.00973  0.627 2.72e-3
## # … with 190 more rows</code></pre>
<p>Focusing on the <code>augment()</code> output, we see there are 136 rows - indeed there are 136 crabs!! Each row represents an outcome from the model. The particular columns we may want are <code>.fitted</code> and <code>.resid</code>:</p>
<ul>
<li>
<code>.fitted</code>: What does the model formula give for the response at this predictor? For example, row 1 is an observation with carapace length of 16.1 mm and body depth of 7 mm. If I put the <em>predictor</em> 16.1 into the model <em><span class="math inline">\(Y = 0.473X - 1.16\)</span></em>, I’d get: <span class="math inline">\((0.473\times16.1) - 1.16 = 6.46\)</span>!! We won’t use this quantity now, but it’s really nice to know about.</li>
<li>
<code>.resid</code>: The residual associated with that row - this column contains our residuals!!!</li>
</ul>
<p>For making QQ plots, we’ll use the base R functions <code><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm()</a></code> (for a <strong>norm</strong>al distribution QQ plot) and <code><a href="https://rdrr.io/r/stats/qqnorm.html">qqline()</a></code> (in this case base R is a lot easier than ggplot2). They are run as <em>separate commands entirely</em>, but R will always assume <code><a href="https://rdrr.io/r/stats/qqnorm.html">qqline()</a></code> should go on top of the <em>most recently run QQ plot</em>:</p>
<div class="sourceCode" id="cb14"><html><body><pre class="r"><span class="co">## plot</span>
<span class="kw pkg">broom</span><span class="kw ns">::</span><span class="fu"><a href="https://broom.tidymodels.org/reference/reexports.html">augment</a></span>(<span class="no">model_fit</span>) <span class="kw">-&gt;</span> <span class="no">augmented_fit</span>

<span class="co"># plot the .resid column (yes it starts with a period), and add a line for visual guidance. </span>
<span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm</a></span>(<span class="no">augmented_fit</span>$<span class="no">.resid</span>)
<span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqline</a></span>(<span class="no">augmented_fit</span>$<span class="no">.resid</span>, <span class="kw">col</span> <span class="kw">=</span> <span class="st">"red"</span>)  <span class="co">#Spielman personal preference, I like making it a color. base R uses "col"</span></pre></body></html></div>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-12-1.png" width="700"></p>
<p>This is pretty good, but could be better - the tails of the plot, in particular the right, have a bit of deviation, but not so much that I’d worry. So, I’m satisified with the assumptions being met for this model.</p>
<p><em>Here are examples of how the plot might look when it’s time to start worrying:</em> <img src="08_linear_models_files/figure-html/unnamed-chunk-13-1.png" width="960"></p>
<p><strong>Notably</strong> there is another neat way to get the residuals using the package <code>modelr</code> (within <code>tidyverse</code>, but needs to be loaded). We will use several more functions from this VERY helpful (but caution, often times very advanced) package soon!. The function <code>add_residuals()</code> can be used this way:</p>
<div class="sourceCode" id="cb15"><html><body><pre class="r"><span class="co">## first argument is the data itself, second is the model object</span>
<span class="co">## output column `resid` contains the goods</span>
<span class="kw pkg">modelr</span><span class="kw ns">::</span><span class="fu"><a href="https://modelr.tidyverse.org/reference/add_residuals.html">add_residuals</a></span>(<span class="no">crabs</span>, <span class="no">model_fit</span>)</pre></body></html></div>
<pre><code>## # A tibble: 200 x 8
##    color sex   frontal_lobe rear_width carapace_length carapace_width body_depth
##    &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;      &lt;dbl&gt;
##  1 blue  M              8.1        6.7            16.1           19          7  
##  2 blue  M              8.8        7.7            18.1           20.8        7.4
##  3 blue  M              9.2        7.8            19             22.4        7.7
##  4 blue  M              9.6        7.9            20.1           23.1        8.2
##  5 blue  M              9.8        8              20.3           23          8.2
##  6 blue  M             10.8        9              23             26.5        9.8
##  7 blue  M             11.1        9.9            23.8           27.1        9.8
##  8 blue  M             11.6        9.1            24.5           28.4       10.4
##  9 blue  M             11.8        9.6            24.2           27.8        9.7
## 10 blue  M             11.8       10.5            25.2           29.3       10.3
## # … with 190 more rows, and 1 more variable: resid &lt;dbl&gt;</code></pre>
</div>
<div id="simple-anova-single-categorical-predictor" class="section level3">
<h3 class="hasAnchor">
<a href="#simple-anova-single-categorical-predictor" class="anchor"></a>Simple ANOVA: Single categorical predictor</h3>
<p>What if, rather than a numeric predictor (carapace Length), we had a <em>categorical</em> predictor, say sex? Here we might ask: <strong>Does sex predict body depth in crabs</strong>? In the context of running an explicit ANOVA, one might phrase it as: <strong>Does the variation in body depth differ across sex in crabs?</strong> They are in fact the same question!</p>
<p>Again, begin with a quick-and-dirty visualization. Here we’d like to see that the distribution of body depths has similar <em>spread</em> across sex categories (the assumption of equal variance for categorical predictors!). Indeed, these two distributions show similar amounts of spread (how much relative space along the Y axis they take up), so assumption is met.</p>
<div class="sourceCode" id="cb17"><html><body><pre class="r"><span class="fu">ggplot</span>(<span class="no">crabs</span>, <span class="fu">aes</span>(<span class="kw">x</span> <span class="kw">=</span> <span class="no">sex</span>, <span class="kw">y</span> <span class="kw">=</span> <span class="no">body_depth</span>, <span class="kw">color</span><span class="kw">=</span><span class="no">sex</span>)) + <span class="fu">geom_jitter</span>()</pre></body></html></div>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-15-1.png" width="384"></p>
<p>Let’s run the model:</p>
<div class="sourceCode" id="cb18"><html><body><pre class="r"><span class="co">## perform linear model and save as model_fit</span>
<span class="no">model_fit</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span>(<span class="no">body_depth</span> ~ <span class="no">sex</span>, <span class="kw">data</span> <span class="kw">=</span> <span class="no">crabs</span>)

<span class="co">## view output with summary(). </span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="no">model_fit</span>)</pre></body></html></div>
<pre><code>## 
## Call:
## lm(formula = body_depth ~ sex, data = crabs)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -7.624 -2.449  0.076  2.463  7.376 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  13.7240     0.3420  40.134   &lt;2e-16 ***
## sexM          0.6130     0.4836   1.268    0.206    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.42 on 198 degrees of freedom
## Multiple R-squared:  0.00805,    Adjusted R-squared:  0.00304 
## F-statistic: 1.607 on 1 and 198 DF,  p-value: 0.2064</code></pre>
<p><strong>This is where the order of categorical variables become really important</strong>: All linear model output when categorical predictors are used assumes a given level of the categorical variable. Unless you re-factor a variable explicitly, levels will be used in alphabetical order - here, “F” comes before “M”.</p>
<p>Coefficients associated with categorical predictors have a somewhat different interpretation</p>
<p>We see the intercept is highly significant (<em>P&lt;2e-16</em>) with a value of 13.724. <strong>Intercepts for a model with a categorical predictor mean: What is the expected body depth of the baseline level, which in this case is “F” (female)?</strong>. We expect the average female crab to have a body depth of 13.72 mm. This is the “categorical” analogy of a standard intercept that would be interpreted as, “what is body depth when sex is 0?”. Of course, as a categorical variable, sex cannot be 0 - it’s F or M in this dataset.</p>
<p>The coefficient associated with SexM means, <strong>How does being male influence body depth relative to the factor baseline, female?</strong> On average, males have body depth 0.613 mm larger than females. (Notably, for a categorical variable with <em>N</em> levels, there will be see <em>N-1</em> coefficients). In this case, however, the P-value is NOT significant (P=0.206). Similarly our adjusted <em>R^2</em> is not significant. Therefore, we actually do not see evidence that the average male body depth differs from the average female body depth.</p>
<p><strong>This model therefore tells us: sex is NOT explanatory of body depth in crabs!</strong> Either way, let’s think how we might visualize the model results. The strip plot used above to check assumptions is a pretty good way to do it, or any other way to show distributions. That said, these models operate on <em>means</em>, so it might be useful to actually visualize the means specifically. A neat trick for doing this comes from <code>stat_summary()</code>!!</p>
<div class="sourceCode" id="cb20"><html><body><pre class="r"><span class="fu">ggplot</span>(<span class="no">crabs</span>, <span class="fu">aes</span>(<span class="kw">x</span> <span class="kw">=</span> <span class="no">sex</span>, <span class="kw">y</span> <span class="kw">=</span> <span class="no">body_depth</span>, <span class="kw">color</span> <span class="kw">=</span> <span class="no">sex</span>)) +
  <span class="fu">geom_jitter</span>() +
  <span class="fu">labs</span>(<span class="kw">x</span> <span class="kw">=</span> <span class="st">"Sex"</span>, <span class="kw">y</span> <span class="kw">=</span> <span class="st">"Body depth (mm)"</span>) +
  <span class="fu">theme</span>(<span class="kw">legend.position</span> <span class="kw">=</span> <span class="st">"none"</span>) +
  <span class="fu">stat_summary</span>(<span class="kw">fun.data</span> <span class="kw">=</span> <span class="st">"mean_se"</span>, <span class="co"># calculate mean and se</span>
               <span class="kw">color</span> <span class="kw">=</span> <span class="st">"black"</span>)</pre></body></html></div>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-17-1.png" width="576"></p>
<p>As you can see, those means look about identical and their standard errors overlap - it makes sense that the model did <em>not</em> show evidence that sex is predictive of body depth.</p>
<div id="as-an-anova" class="section level4">
<h4 class="hasAnchor">
<a href="#as-an-anova" class="anchor"></a>As an ANOVA</h4>
<p>For posterity, it can’t hurt to see how this looks as a bonafide ANOVA table using the function <code><a href="https://rdrr.io/r/stats/aov.html">aov()</a></code>:</p>
<div class="sourceCode" id="cb21"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/stats/aov.html">aov</a></span>(<span class="no">model_fit</span>) <span class="kw">-&gt;</span> <span class="no">anova_model_fit</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="no">anova_model_fit</span>)</pre></body></html></div>
<pre><code>##              Df Sum Sq Mean Sq F value Pr(&gt;F)
## sex           1   18.8   18.79   1.607  0.206
## Residuals   198 2315.3   11.69</code></pre>
</div>
</div>
<div id="lm-with-numeric-and-categorical-predictors" class="section level3">
<h3 class="hasAnchor">
<a href="#lm-with-numeric-and-categorical-predictors" class="anchor"></a>LM with numeric and categorical predictors</h3>
<p>Let’s see how to run and interpret a model with BOTH numeric and categorical predictors. We will examine how color and carapace length together might be predictive of body depth in crabs. Said otherwise: We’ve seen how carapace length influences body depth. Does this effect persist when controlling for color? Importantly, when you have multiple predictors, the model assumes they are FULLY INDEPENDENT and ENTIRELY UNRELATED. Of course this is not always true - read on to learn more about how to deal with this issue!</p>
<p>Let’s run the model with multiple predictors, which we simply add together in the formula</p>
<div class="sourceCode" id="cb23"><html><body><pre class="r"><span class="co">## order of predictors does NOT matter</span>
<span class="no">model_fit</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span>(<span class="no">body_depth</span> ~ <span class="no">color</span> + <span class="no">carapace_length</span>, <span class="kw">data</span> <span class="kw">=</span> <span class="no">crabs</span>)

<span class="co">## view output with summary(). </span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="no">model_fit</span>)
<span class="co">## </span>
<span class="co">## Call:</span>
<span class="co">## lm(formula = body_depth ~ color + carapace_length, data = crabs)</span>
<span class="co">## </span>
<span class="co">## Residuals:</span>
<span class="co">##      Min       1Q   Median       3Q      Max </span>
<span class="co">## -1.31623 -0.22544  0.00332  0.27120  1.08043 </span>
<span class="co">## </span>
<span class="co">## Coefficients:</span>
<span class="co">##                  Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">## (Intercept)     -0.996643   0.123044   -8.10 5.65e-14 ***</span>
<span class="co">## colororange      1.044956   0.055373   18.87  &lt; 2e-16 ***</span>
<span class="co">## carapace_length  0.451781   0.003899  115.87  &lt; 2e-16 ***</span>
<span class="co">## ---</span>
<span class="co">## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">## </span>
<span class="co">## Residual standard error: 0.3749 on 197 degrees of freedom</span>
<span class="co">## Multiple R-squared:  0.9881, Adjusted R-squared:  0.988 </span>
<span class="co">## F-statistic:  8204 on 2 and 197 DF,  p-value: &lt; 2.2e-16</span></pre></body></html></div>
<p>When considering BOTH color and carapace length as model predictors, we find:</p>
<ul>
<li>The intercept means your average blue (the baseline level of <code>color</code>) crab <em>with a carapace length of 0</em> has a body depth of -0.997 mm. It’s highly sigificant but unrealistic - moving on.</li>
<li>The “colororange” means <em>when controlling for carapace length</em>, your average orange crab’s body depth will be ~1.045 mm larger than an average crab. Again, highly significant.</li>
<li>The “carapace_length” coefficient means <em>when controlling for color</em>, the average crab’s body depth increases by 0.452 per 1 mm increase in carapace length, and it’s highly significant.</li>
<li>The predictors explain <em>~98.8%</em> of the variation in body depth - our model appears to have improved in predictive ability by jointly considering color with carapace length! A mere 1.2% of variation in body depth is unexplained by the two significant predictors.</li>
</ul>
<p>Let’s check our residuals as well with a QQ plot. We find that they are indeed normally distributed, so the model’s assumptions have been met and we can rely on its output.</p>
<div class="sourceCode" id="cb24"><html><body><pre class="r"><span class="fu">augment</span>(<span class="no">model_fit</span>) <span class="kw">-&gt;</span> <span class="no">augmented_fit</span>
<span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm</a></span>(<span class="no">augmented_fit</span>$<span class="no">.resid</span>)
<span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqline</a></span>(<span class="no">augmented_fit</span>$<span class="no">.resid</span>, <span class="kw">col</span><span class="kw">=</span><span class="st">"red"</span>)</pre></body></html></div>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-20-1.png" width="700"></p>
<p><strong>How can we visualize this model?</strong> We can again make a scatterplot, and show the trend lines for each sex:</p>
<div class="sourceCode" id="cb25"><html><body><pre class="r"><span class="fu">ggplot</span>(<span class="no">crabs</span>, <span class="fu">aes</span>(<span class="kw">x</span> <span class="kw">=</span> <span class="no">carapace_length</span>, <span class="kw">y</span> <span class="kw">=</span> <span class="no">body_depth</span>, <span class="kw">color</span> <span class="kw">=</span> <span class="no">color</span>)) +
  <span class="fu">geom_point</span>() +
  <span class="fu">labs</span>(<span class="kw">x</span> <span class="kw">=</span> <span class="st">"Carapace length (mm)"</span>,
       <span class="kw">y</span> <span class="kw">=</span> <span class="st">"Body Depth (mm)"</span>,
       <span class="kw">color</span> <span class="kw">=</span> <span class="st">"Crab color"</span>) +
  <span class="fu">scale_color_manual</span>(<span class="kw">values</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"blue"</span>, <span class="st">"orange"</span>)) + <span class="co"># why not!</span>
  <span class="fu">geom_smooth</span>(<span class="kw">method</span> <span class="kw">=</span> <span class="st">"lm"</span>) +
  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="kw">x</span> <span class="kw">=</span> <span class="fl">20</span>, <span class="kw">y</span> <span class="kw">=</span> <span class="fl">30</span>, <span class="kw">label</span> <span class="kw">=</span> <span class="st">"R^2 == 0.988"</span>, <span class="kw">parse</span><span class="kw">=</span><span class="no">T</span>, <span class="kw">size</span><span class="kw">=</span><span class="fl">5</span>)</pre></body></html></div>
<pre><code>## `geom_smooth()` using formula 'y ~ x'</code></pre>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-21-1.png" width="576"></p>
</div>
<div id="lm-with-multiple-numeric-predictors" class="section level3">
<h3 class="hasAnchor">
<a href="#lm-with-multiple-numeric-predictors" class="anchor"></a>LM with multiple numeric predictors</h3>
<p>Now we will look at a model with multiple numeric predictors, carapace width <em>and</em> carapace length. We know already that carapace length has a linear relationship with body depth from earlier in this document, so let’s just check out the linearity of body depth/carapace width. Indeed, the relationship is linear, so let’s proceed.</p>
<div class="sourceCode" id="cb27"><html><body><pre class="r"><span class="fu">ggplot</span>(<span class="no">crabs</span>, <span class="fu">aes</span>(<span class="kw">x</span> <span class="kw">=</span> <span class="no">carapace_width</span>, <span class="kw">y</span> <span class="kw">=</span> <span class="no">body_depth</span>)) + <span class="fu">geom_point</span>()</pre></body></html></div>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-22-1.png" width="288"></p>
<p>Again, we can simply add predictors together (order does not matter!):</p>
<div class="sourceCode" id="cb28"><html><body><pre class="r"><span class="co">## perform linear model and save as model_fit</span>
<span class="no">model_fit</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span>(<span class="no">body_depth</span> ~ <span class="no">carapace_width</span> + <span class="no">carapace_length</span>, <span class="kw">data</span> <span class="kw">=</span> <span class="no">crabs</span>)

<span class="co">## view output with summary(). </span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="no">model_fit</span>)</pre></body></html></div>
<pre><code>## 
## Call:
## lm(formula = body_depth ~ carapace_width + carapace_length, data = crabs)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.78651 -0.35206 -0.01679  0.35397  1.61916 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     -0.65396    0.17540  -3.728 0.000252 ***
## carapace_width  -0.45995    0.04636  -9.922  &lt; 2e-16 ***
## carapace_length  0.97907    0.05126  19.099  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.513 on 197 degrees of freedom
## Multiple R-squared:  0.9778, Adjusted R-squared:  0.9776 
## F-statistic:  4336 on 2 and 197 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Our model has found:</p>
<ul>
<li>You average crab with carapace width and carapace length both equal to zero will have, on average, a body depth of -0.65, and this is highly significant at <em>P=0.000252</em>. But of course, this is not biologically meaningful - it just is needed to build the model.</li>
<li>On average, we expect that body depth <em>decreases</em> by ~0.46 when carapace width increases by 1 mm, <em>assuming carapace LENGTH is unchanged</em>. This is also highly significant.</li>
<li>On average, we expect that body depth <em>increases</em> by ~0.979 when carapace length increases 1 mm, <em>assuming carapace WIDTH is unchanged</em>. This is also highly significant.</li>
<li>The independent effects of carapace length and width explain roughly 97.76% of variation in body depth, and it is highly significant.</li>
</ul>
<p>A quick check of residuals also shows normality, so we’re all set.</p>
<div class="sourceCode" id="cb30"><html><body><pre class="r"><span class="fu">augment</span>(<span class="no">model_fit</span>) <span class="kw">-&gt;</span> <span class="no">augmented_fit</span>
<span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm</a></span>(<span class="no">augmented_fit</span>$<span class="no">.resid</span>)
<span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqline</a></span>(<span class="no">augmented_fit</span>$<span class="no">.resid</span>, <span class="kw">col</span><span class="kw">=</span><span class="st">"red"</span>)</pre></body></html></div>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-24-1.png" width="700"></p>
<p>We could visualize this if we want by putting on predictor on the X, and using color to disinguish the other predictor. That said, it is very difficult to make scatterplot visualizations with multiple numeric predictors, especially since we can’t draw two trend lines in one set of axes.</p>
<div class="sourceCode" id="cb31"><html><body><pre class="r"><span class="fu">ggplot</span>(<span class="no">crabs</span>, <span class="fu">aes</span>(<span class="kw">x</span> <span class="kw">=</span> <span class="no">carapace_length</span>, <span class="kw">y</span> <span class="kw">=</span> <span class="no">body_depth</span>, <span class="kw">color</span> <span class="kw">=</span> <span class="no">carapace_width</span>)) +
  <span class="fu">geom_point</span>(<span class="kw">size</span> <span class="kw">=</span> <span class="fl">2.5</span>) + <span class="co"># i like the plot with bigger points </span>
  <span class="fu">labs</span>(<span class="kw">x</span> <span class="kw">=</span> <span class="st">"Carapace length (mm)"</span>,
       <span class="kw">y</span> <span class="kw">=</span> <span class="st">"Body depth (mm)"</span>,
       <span class="kw">color</span> <span class="kw">=</span> <span class="st">"Carapace width (mm)"</span>) +
  <span class="fu">scale_color_distiller</span>(<span class="kw">palette</span> <span class="kw">=</span> <span class="st">"Reds"</span>) +
  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="kw">x</span> <span class="kw">=</span> <span class="fl">20</span>, <span class="kw">y</span> <span class="kw">=</span> <span class="fl">30</span>, <span class="kw">label</span> <span class="kw">=</span> <span class="st">"R^2 == 0.977"</span>, <span class="kw">parse</span><span class="kw">=</span><span class="no">T</span>, <span class="kw">size</span><span class="kw">=</span><span class="fl">5</span>) +
  <span class="fu">theme</span>(<span class="kw">legend.position</span> <span class="kw">=</span> <span class="st">"bottom"</span>) <span class="co"># again my personal preference</span></pre></body></html></div>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-25-1.png" width="576"></p>
</div>
<div id="lm-with-interaction-effects" class="section level3">
<h3 class="hasAnchor">
<a href="#lm-with-interaction-effects" class="anchor"></a>LM with interaction effects</h3>
<p>So far, we have fit TWO models that have multiple predictors: 1) using color and carapace length, and 2) using carapace width and carapace length. Both models made the assumption that all predictors are independent of one another, e.g. carapace width and length are independent (in statistical terms, we’d say those models used “additive effects”). Of course, this is unlikely to be the case. In addition, it is possible that the effects of carapace length on body depth <em>depend</em> on carapace width, and vice versa. We would call this an <strong>interaction effect.</strong></p>
<p>As a general rule, when you have multiple predictors for a linear model, it is usually a good idea to FIRST run the model assuming an interaction effect. If the interaction effect is not significant, use an additive model instead. If the interaction effect IS significant, <em>ignore</em> the additive effects and report only on the interaction effects. Indeed, if there is a significant interaction, it no longer makes sense to focus on individual contributions.</p>
<div id="example-1" class="section level4">
<h4 class="hasAnchor">
<a href="#example-1" class="anchor"></a>Example #1</h4>
<p>Previously, we looked at the explanatory power of carapace length and color on body depth as independent effects. What if they are not independent, however? Looking at the visualization we made from this model, we see that the two regression lines for each crab color are roughly parallel - this suggests that the relationship between carapace length and body depth is consistent regardless of color. This would mean NO interaction effect, but we can formally test this out by adding an interaction term to the model:</p>
<div class="sourceCode" id="cb32"><html><body><pre class="r"><span class="co"># interact by using * instead of + for predictors</span>
<span class="no">model_fit</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span>(<span class="no">body_depth</span> ~ <span class="no">carapace_length</span> * <span class="no">color</span>, <span class="kw">data</span> <span class="kw">=</span> <span class="no">crabs</span>)
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="no">model_fit</span>)</pre></body></html></div>
<pre><code>## 
## Call:
## lm(formula = body_depth ~ carapace_length * color, data = crabs)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.22825 -0.19428 -0.01018  0.22544  1.01383 
## 
## Coefficients:
##                              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                 -0.667829   0.165192  -4.043 7.59e-05 ***
## carapace_length              0.440842   0.005358  82.282  &lt; 2e-16 ***
## colororange                  0.327083   0.252010   1.298  0.19585    
## carapace_length:colororange  0.022331   0.007655   2.917  0.00394 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.368 on 196 degrees of freedom
## Multiple R-squared:  0.9886, Adjusted R-squared:  0.9885 
## F-statistic:  5681 on 3 and 196 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>In this output…</p>
<ul>
<li>
<strong>carapace_length</strong> is the <em>independent</em> coefficient for carapace_length</li>
<li>
<strong>colororange</strong> is the <em>independent</em> coefficient for color</li>
<li>
<strong>carapace_length:colororange</strong> is the <em>interaction effect</em> coefficient for caparace length x color, and it is in fact significant at <em>P=0.00394</em>!! Indeed, there <strong>is</strong> a significant difference in trend between crab colors. However it’s quite hard to see in the plot - this is a great example of when statistical significance corresponds to only moderate, in this case, small, effect size.</li>
</ul>
<p>Our residuals are also normally distributed:</p>
<div class="sourceCode" id="cb34"><html><body><pre class="r"><span class="fu">augment</span>(<span class="no">model_fit</span>) <span class="kw">-&gt;</span> <span class="no">augmented_fit</span>
<span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm</a></span>(<span class="no">augmented_fit</span>$<span class="no">.resid</span>)
<span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqline</a></span>(<span class="no">augmented_fit</span>$<span class="no">.resid</span>, <span class="kw">col</span><span class="kw">=</span><span class="st">"red"</span>)</pre></body></html></div>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-27-1.png" width="700"></p>
<p>Upon finding a significant interaction effect, we promptly <em>ignore</em> any independent effects - since the interaction tells us these variables are not independent, it does not make sense to consider their independent influence on body depth. We have evidence that the way that carapace length affects body depth depends on color! Similarly, the way that color affects body depth depends on carapace length.</p>
<p>The best way to interpret this model is not to focus on the interaction term coefficient (they’re a little tricky..), but rather to make a plot like we did earlier with the two slopes, and see how those slopes potentially cross or interact, or in this case are only barely non-parallel. In fact, although small, these slopes are NOT identical and the lines are NOT exactly parallel - there is a significant interaction! However, it is of course a very small effect size. <strong>The punchline here is that the interaction is significant, so we have evidence that carapace length and color INTERACT when explaining body depth.</strong></p>
<div class="sourceCode" id="cb35"><html><body><pre class="r"><span class="fu">ggplot</span>(<span class="no">crabs</span>, <span class="fu">aes</span>(<span class="kw">x</span> <span class="kw">=</span> <span class="no">carapace_length</span>, <span class="kw">y</span> <span class="kw">=</span> <span class="no">body_depth</span>, <span class="kw">color</span> <span class="kw">=</span> <span class="no">color</span>)) +
  <span class="fu">geom_point</span>() +
  <span class="fu">labs</span>(<span class="kw">x</span> <span class="kw">=</span> <span class="st">"Carapace length (mm)"</span>,
       <span class="kw">y</span> <span class="kw">=</span> <span class="st">"Body Depth (mm)"</span>,
       <span class="kw">color</span> <span class="kw">=</span> <span class="st">"Crab color"</span>) +
  <span class="fu">scale_color_manual</span>(<span class="kw">values</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"blue"</span>, <span class="st">"orange"</span>)) +
  <span class="fu">geom_smooth</span>(<span class="kw">method</span> <span class="kw">=</span> <span class="st">"lm"</span>) +
  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="kw">x</span> <span class="kw">=</span> <span class="fl">20</span>, <span class="kw">y</span> <span class="kw">=</span> <span class="fl">30</span>, <span class="kw">label</span> <span class="kw">=</span> <span class="st">"R^2 == 0.988"</span>, <span class="kw">parse</span><span class="kw">=</span><span class="no">T</span>, <span class="kw">size</span><span class="kw">=</span><span class="fl">5</span>)</pre></body></html></div>
<pre><code>## `geom_smooth()` using formula 'y ~ x'</code></pre>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-28-1.png" width="576"></p>
<p>NOTE: It is possible to directly specify the interaction effect to the linear model like so - in fact the interaction effect is a <em>third term</em> in the model:</p>
<div class="sourceCode" id="cb37"><html><body><pre class="r"><span class="no">model_fit</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span>(<span class="no">body_depth</span> ~ <span class="no">carapace_length</span> + <span class="no">color</span> + <span class="no">carapace_length</span>:<span class="no">color</span>, <span class="kw">data</span> <span class="kw">=</span> <span class="no">crabs</span>)
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="no">model_fit</span>)</pre></body></html></div>
<pre><code>## 
## Call:
## lm(formula = body_depth ~ carapace_length + color + carapace_length:color, 
##     data = crabs)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.22825 -0.19428 -0.01018  0.22544  1.01383 
## 
## Coefficients:
##                              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                 -0.667829   0.165192  -4.043 7.59e-05 ***
## carapace_length              0.440842   0.005358  82.282  &lt; 2e-16 ***
## colororange                  0.327083   0.252010   1.298  0.19585    
## carapace_length:colororange  0.022331   0.007655   2.917  0.00394 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.368 on 196 degrees of freedom
## Multiple R-squared:  0.9886, Adjusted R-squared:  0.9885 
## F-statistic:  5681 on 3 and 196 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="example-2" class="section level4">
<h4 class="hasAnchor">
<a href="#example-2" class="anchor"></a>Example #2</h4>
<p>Let’s do another interaction model by considering two <em>categorical predictors</em>, sex and color. This can be visualized with an <em>interaction plot</em> which explictly show how the <em>mean response</em> (here, mean body depth) depends on levels of two categorical predictor:</p>
<div class="sourceCode" id="cb39"><html><body><pre class="r"><span class="no">crabs</span> <span class="kw">%&gt;%</span>
  <span class="co">## get mean body depth per group first</span>
  <span class="fu">group_by</span>(<span class="no">sex</span>, <span class="no">color</span>) <span class="kw">%&gt;%</span>
  <span class="fu">summarize</span>(<span class="kw">mean_body_depth</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>(<span class="no">body_depth</span>)) <span class="kw">%&gt;%</span>
  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="kw">x</span> <span class="kw">=</span> <span class="no">sex</span>, <span class="kw">y</span> <span class="kw">=</span> <span class="no">mean_body_depth</span>, <span class="kw">color</span> <span class="kw">=</span> <span class="no">color</span>)) +
    <span class="fu">geom_point</span>() +
    <span class="fu">geom_path</span>(<span class="fu">aes</span>(<span class="kw">group</span> <span class="kw">=</span> <span class="no">color</span>)) +
    <span class="fu">scale_color_manual</span>(<span class="kw">values</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"blue"</span>,<span class="st">"orange"</span>))</pre></body></html></div>
<pre><code>## `summarise()` regrouping output by 'sex' (override with `.groups` argument)</code></pre>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-30-1.png" width="432"></p>
<p>This plot suggests potential interaction effect! It seems female orange crabs have higher mean body depths compared to male orange crabs, but the opposite appears true blue. Notably, you see the <em>slopes of these lines do not match.</em> (Lines have the same slope - the effect of sex does NOT appear to depend on Color.) A linear model will tell us if this potential interaction is significant - but note the tiny tiny breaks on the Y-axis? If there is a significant interation, it will likely have a very small effect size.</p>
<p>Let’s go ahead and see:</p>
<div class="sourceCode" id="cb41"><html><body><pre class="r"><span class="co"># interact by using * instead of + for predictors</span>
<span class="no">model_fit</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span>(<span class="no">body_depth</span> ~ <span class="no">sex</span> * <span class="no">color</span>, <span class="kw">data</span> <span class="kw">=</span> <span class="no">crabs</span>)
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="no">model_fit</span>)</pre></body></html></div>
<pre><code>## 
## Call:
## lm(formula = body_depth ~ sex * color, data = crabs)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -7.924 -2.224  0.059  2.250  6.650 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       11.8160     0.4349  27.167  &lt; 2e-16 ***
## sexM               1.5340     0.6151   2.494   0.0135 *  
## colororange        3.8160     0.6151   6.204 3.21e-09 ***
## sexM:colororange  -1.8420     0.8699  -2.118   0.0355 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.075 on 196 degrees of freedom
## Multiple R-squared:  0.2058, Adjusted R-squared:  0.1936 
## F-statistic: 16.93 on 3 and 196 DF,  p-value: 8.131e-10</code></pre>
<p>In this output…</p>
<ul>
<li>
<strong>sexM</strong> is the <em>independent</em> coefficient for sex</li>
<li>
<strong>colororange</strong> is the <em>independent</em> coefficient for color</li>
<li>
<strong>sexM:colororange</strong> is the <em>interaction effect</em> coefficient for sex x color, and it is moderately significant at <em>P=0.0355</em>.</li>
</ul>
<p>And, residuals again are ok:</p>
<div class="sourceCode" id="cb43"><html><body><pre class="r"><span class="fu">augment</span>(<span class="no">model_fit</span>) <span class="kw">-&gt;</span> <span class="no">augmented_fit</span>
<span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm</a></span>(<span class="no">augmented_fit</span>$<span class="no">.resid</span>)
<span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqline</a></span>(<span class="no">augmented_fit</span>$<span class="no">.resid</span>, <span class="kw">col</span><span class="kw">=</span><span class="st">"red"</span>)</pre></body></html></div>
<p><img src="08_linear_models_files/figure-html/unnamed-chunk-32-1.png" width="700"></p>
<p>The best way to interpret this model is to a) identify if an interaction is significant, and b) compare the means with an interaction plot. We’ve basically done all those steps, so we are set!</p>
</div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by April Wright.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
